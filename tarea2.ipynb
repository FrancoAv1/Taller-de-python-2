{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "\n",
    "En esta tarea se muestra el proceso de preparación\n",
    "y visualización de datos para su posterior análisis.\n",
    "\n",
    "1. [Seleccion y carga de datos](#0)\n",
    "1. [Limpieza de datos](#1)\n",
    "1. [Estandarizar datos de entrada](#2)\n",
    "1. [Visualización de gráficos](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se instalan en caso de ser necesario las librerías a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importan bibliotecas necesarias para el procesamiento de la base de datos y la posterior visualización de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa las bibliotecas Pandas, Numpy\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Seleccion y carga de datos <a id=\"0\"></a>\n",
    "Para esta tarea se ha seleccionado la base de datos \"Chile earthquakes\" que contiene datos de terremotos ocurridos en Chile entre los años 1520 y 2020.\n",
    "\n",
    "Descripcion de las columnas:\n",
    "\n",
    "- \"Year\": año del terremoto\n",
    "- \"Mo\": mes del terremoto\n",
    "- \"Dy\": dia del terremoto\n",
    "- \"Hr\": hora del terremoto\n",
    "- \"Mn\": minuto del terremoto\n",
    "- \"Tsu\": id del tsunami asociado al terremoto en caso de que ocurriese \n",
    "- \"Country\": Chile\n",
    "- \"Location Name\": region de Chile\n",
    "- \"Latitude\": latitud del epicentro del terremoto\n",
    "- \"Longitude\": longitud del epicentro del terremoto\n",
    "- \"Focal Depth (km)\": profundidad del epicentro del terremoto\n",
    "- \"Mag\": magnitud en escala de Richter del terremoto\n",
    "- \"Deaths\": numero de personas fallecidas asociadas al terremoto\n",
    "- \"Missing\" numero de personas perdidas asociadas con el terremoto\n",
    "- \"Injuries\": numero de personas lesionadas asociadas con el terremoto\n",
    "- \"Damage ($Mil)\": costo total del terremoto\n",
    "- \"Houses Destroyed\": numero total de casas destruidas\n",
    "- \"Houses Damaged\": numero total de casas dañadas\n",
    "\n",
    "#### A continuacion se lee la base de datos y se guarda para su manipulación en una variable llamada \"df\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubicacion = \"./datos/chile_earthquakes_1520-2024.tsv\"\n",
    "\n",
    "directorio_salida = \"./salida/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como la base de datos trae las etiquetas de cada columna, se crea una lista de encabezados para la base de datos y se asigna a la variable \"encabezado\", de esta forma es posible identificar el encabezado de cada columna y posteriormente identificar una columna mediante este mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una lista con el encabezado\n",
    "encabezado = [\"Search Parameters\",\t\"Year\",\t\"Mo\",\t\"Dy\",\t\"Hr\",\t\"Mn\",\t\"Tsu\",\t\"Country\",\t\"Location Name\",\t\"Latitude\",\t\"Longitude\",\t\"Focal Depth (km)\",\t\"Mag\",\t\"Deaths\",\t\"Missing\",\t\"Injuries\",\t\"Damage ($Mil)\",\t\"Houses Destroyed\",\t\"Houses Damaged\"]\n",
    "df = pd.read_csv(ubicacion, sep='\\t', names=encabezado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(OPCIONAL) Comprobar que los encabezados se guardaron correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"headers\\n\", encabezado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(OPCIONAL) Comprobar que los datos se cargaron correctamente mediante la visualización de las primeras 10 filas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpieza de datos <a id=\"1\"></a>\n",
    "Para su posterior visualización y análisis, se procede a limpiar la base de datos de datos innecesarios o nulos mediante diferentes metodos.\n",
    "\n",
    "- Eliminacion de fila innecesaria para el analisis de datos: en este caso se identifican columnas que no entregan información relevante la fila 0 y 1 y la columna con el encabezado \"Search Parameters\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina las filas 0 y 1\n",
    "df = df.drop([0, 1])\n",
    "\n",
    "# Reinicia los índices\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Elimina la columna \"Search Parameters\"\n",
    "df = df.drop(\"Search Parameters\", axis=1)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un analisis basico de los datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Información y análisis estadístico\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión del dataframe (rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_faltantes = df.isnull()\n",
    "datos_faltantes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in datos_faltantes.columns.values.tolist():\n",
    "    print('columna:',columna)\n",
    "    print (datos_faltantes[columna].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de valores faltantes en cada columna\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manipulación de valores faltantes: Reemplazando por su frecuencia las columnas \"Mo\", \"Dy\", \"Hr\" y \"Mn\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio de la columna \"Mo\"\n",
    "Mo_prom = df[\"Mo\"].astype(\"float\").mean(axis=0)\n",
    "\n",
    "# Redondea el promedio al entero más cercano\n",
    "Mo_prom_entero = int(round(Mo_prom))\n",
    "\n",
    "# Reemplaza los valores faltantes en la columna \"Mo\" por su promedio entero\n",
    "df[\"Mo\"].fillna(Mo_prom_entero, inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio de la columna \"Dy\"\n",
    "Dy_prom = df[\"Dy\"].astype(\"float\").mean(axis=0)\n",
    "\n",
    "# Redondea el promedio al entero más cercano\n",
    "Dy_prom_entero = int(round(Dy_prom))\n",
    "\n",
    "# Reemplaza los valores faltantes en la columna \"Dy\" por su promedio entero\n",
    "df[\"Dy\"].fillna(Dy_prom_entero, inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio de la columna \"Hr\"\n",
    "Hr_prom = df[\"Hr\"].astype(\"float\").mean(axis=0)\n",
    "\n",
    "# Redondea el promedio al entero más cercano\n",
    "Hr_prom_entero = int(round(Hr_prom))\n",
    "\n",
    "# Reemplaza los valores faltantes en la columna \"Hr\" por su promedio entero\n",
    "df[\"Hr\"].fillna(Hr_prom_entero, inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manipulación de valores faltantes: Reemplazando por su promedio los valores faltantes de la columna \"Mn\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio de la columna \"Mn\"\n",
    "Mn_prom = df[\"Mn\"].astype(\"float\").mean(axis=0)\n",
    "\n",
    "# Redondea el promedio al entero más cercano\n",
    "Mn_prom_entero = int(round(Mn_prom))\n",
    "\n",
    "# Reemplaza los valores faltantes en la columna \"Mn\" por su promedio entero\n",
    "df[\"Mn\"].fillna(Mn_prom_entero, inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manipulación de valores faltantes: Reemplazando por 0 los datos faltantes en las columnas \"Tsu\", \"Deaths\" y \"Missing\" de forma de no falsear datos sensibles como lo son estas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplaza los valores faltantes en la columna \"Tsu\", \"Deaths\" y \"Missing\" por 0\n",
    "df[\"Tsu\"].fillna(0, inplace=True)\n",
    "df[\"Deaths\"].fillna(0, inplace=True)\n",
    "df[\"Missing\"].fillna(0, inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manipulación de valores faltantes: Reemplazando por el promedio las columnas \"Focal Depth (km)\", \"Mag\", \"Injuries\" y \"Damage ($Mil)\" de forma de que no afecte al analisis posterior en los gráficos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio de la columna \"Focal Depth (km)\"\n",
    "Focal_depth_prom = df[\"Focal Depth (km)\"].astype(\"float\").mean(axis=0)\n",
    "\n",
    "# Redondea el promedio al entero más cercano\n",
    "Focal_depth_prom_entero = int(round(Focal_depth_prom))\n",
    "\n",
    "# Reemplaza los valores faltantes en la columna \"Focal Depth (km)\" por su promedio entero\n",
    "df[\"Focal Depth (km)\"].fillna(Focal_depth_prom_entero, inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio de la columna \"Mag\"\n",
    "Mag_prom = df[\"Mag\"].astype(\"float\").mean(axis=0)\n",
    "\n",
    "# Reemplaza los valores faltantes en la columna \"Mag\" por el promedio con un decimal\n",
    "df[\"Mag\"].fillna(round(Mag_prom, 1), inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio de la columna \"Injuries\"\n",
    "Injuries_prom = df[\"Injuries\"].astype(\"float\").mean(axis=0)\n",
    "\n",
    "# Redondea el promedio al entero más cercano\n",
    "Injuries_prom_entero = int(round(Injuries_prom))\n",
    "\n",
    "# Reemplaza los valores faltantes en la columna \"Injuries\" por el promedio entero\n",
    "df[\"Injuries\"].fillna(Injuries_prom_entero, inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio para \"Damage ($Mil)\"\n",
    "damage_prom = df[\"Damage ($Mil)\"].astype(\"float\").mean(axis=0)\n",
    "# Redondea el promedio al entero más cercano\n",
    "damage_prom_entero = int(round(damage_prom))\n",
    "# Reemplaza los valores faltantes en \"Damage ($Mil)\" por el promedio entero\n",
    "df[\"Damage ($Mil)\"].fillna(damage_prom_entero, inplace=True)\n",
    "\n",
    "# Calcula el promedio para \"Houses Destroyed\"\n",
    "destroyed_prom = df[\"Houses Destroyed\"].astype(\"float\").mean(axis=0)\n",
    "# Redondea el promedio al entero más cercano\n",
    "destroyed_prom_entero = int(round(destroyed_prom))\n",
    "# Reemplaza los valores faltantes en \"Houses Destroyed\" por el promedio entero\n",
    "df[\"Houses Destroyed\"].fillna(destroyed_prom_entero, inplace=True)\n",
    "\n",
    "# Calcula el promedio para \"Houses Damaged\"\n",
    "damaged_prom = df[\"Houses Damaged\"].astype(\"float\").mean(axis=0)\n",
    "# Redondea el promedio al entero más cercano\n",
    "damaged_prom_entero = int(round(damaged_prom))\n",
    "# Reemplaza los valores faltantes en \"Houses Damaged\" por el promedio entero\n",
    "df[\"Houses Damaged\"].fillna(damaged_prom_entero, inplace=True)\n",
    "\n",
    "# Cantidad actualizada de valores faltantes en cada columna\n",
    "print(df.isnull().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estandarizar datos de entrada. <a id=\"2\"></a>\n",
    "\n",
    "- Se estandarizan los datos de entrada de las columnas que contienen datos numericos de forma que se reconozcan de tipo numerico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_numericas = ['Year', 'Mo', 'Dy', 'Hr', 'Mn', 'Tsu', 'Latitude', 'Longitude', 'Focal Depth (km)', 'Mag', 'Deaths', 'Missing', 'Injuries', 'Damage ($Mil)', 'Houses Destroyed', 'Houses Damaged']\n",
    "print(df[columnas_numericas].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columnas a tipo numérico\n",
    "df[columnas_numericas] = df[columnas_numericas].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Verificar los tipos de datos después de la conversión\n",
    "print(df[columnas_numericas].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupar datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por año y calcular el promedio de la magnitud de los terremotos\n",
    "promedio_magnitud_por_año = df.groupby('Year')['Mag'].mean()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(promedio_magnitud_por_año)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tables\n",
    "# Guardar como archivo CSV en el directorio de salida\n",
    "df.to_csv(directorio_salida + 'datos_procesados.csv', index=False)\n",
    "\n",
    "# Guardar como archivo Excel en el directorio de salida\n",
    "df.to_excel(directorio_salida + 'datos_procesados.xlsx', index=False)\n",
    "\n",
    "# Guardar como archivo HDF5 en el directorio de salida\n",
    "df.to_hdf(directorio_salida + 'datos_procesados.h5', key='df', mode='w')\n",
    "\n",
    "# Guardar como archivo pickle de Python en el directorio de salida\n",
    "df.to_pickle(directorio_salida + 'datos_procesados.pkl')\n",
    "\n",
    "# Guardar como archivo TSV en el directorio de salida\n",
    "df.to_csv(directorio_salida + 'datos_procesados.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualización de datos <a id=\"3\"></a>\n",
    "\n",
    "- Para el analisis de los datos preparados anteriormente se procede a visualizar los datos mediante gráficos de barras y de dispersión, de esta forma se ve más claramente la distribución de los datos al contrastarlo.\n",
    "\n",
    "(Nota: graficos agrupados en una sola celda debido a que no logramos imprimirlos de forma separada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "# Creamos un objeto para el PDF\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"salida/graficos_chile_earthquakes.pdf\")\n",
    "\n",
    "# Gráfico 1: Histograma de Magnitudes\n",
    "plt.hist(df['Mag'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Magnitud (Escala Richter)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución de las Magnitudes de los Terremotos en Chile')\n",
    "pdf.savefig()  # Guardamos este gráfico en el PDF\n",
    "\n",
    "# Gráfico 2: Dispersión de Latitud y Longitud\n",
    "plt.figure(figsize=(8,6))  # Creamos una nueva figura para el siguiente gráfico\n",
    "plt.scatter(df['Longitude'], df['Latitude'], color='green', label='Epicentro del Terremoto')\n",
    "plt.title('Distribución Espacial (Ubicación) de Terremotos en Chile', fontsize=16)\n",
    "plt.xlabel('Longitud', fontsize=14)\n",
    "plt.ylabel('Latitud', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "pdf.savefig()  # Guardamos este gráfico en el PDF\n",
    "\n",
    "# Gráfico 3: Barras de Tsunamis por Año\n",
    "tsunami_events = df[df['Tsu'] != 0]  # Filtrar los eventos de tsunami\n",
    "tsunami_count_by_year = tsunami_events.groupby('Year')['Tsu'].count()\n",
    "plt.figure()  # Creamos una nueva figura para el siguiente gráfico\n",
    "plt.bar(tsunami_count_by_year.index, tsunami_count_by_year.values, color='blue')\n",
    "plt.title('Número de Terremotos con Tsunamis Asociados por Año en Chile', fontsize=16)\n",
    "plt.xlabel('Año', fontsize=14)\n",
    "plt.ylabel('Número de Tsunamis', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "pdf.savefig()  # Guardamos este gráfico en el PDF\n",
    "\n",
    "# Gráfico 4: Línea de Magnitud vs. Año\n",
    "plt.figure(figsize=(20, 10))  # Creamos una nueva figura para el siguiente gráfico\n",
    "plt.plot(df['Year'], df['Mag'], marker='o', linestyle='-')\n",
    "plt.title('Magnitud de los Terremotos en Chile a lo largo del Tiempo')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Magnitud')\n",
    "plt.grid(True)\n",
    "pdf.savefig()  # Guardamos este gráfico en el PDF\n",
    "\n",
    "# Gráfico 5: Dispersión de Magnitud vs. Profundidad Focal\n",
    "plt.figure()  # Creamos una nueva figura para el siguiente gráfico\n",
    "plt.scatter(df['Focal Depth (km)'], df['Mag'], color='blue', alpha=0.5)\n",
    "plt.title('Magnitud vs. Profundidad Focal de los Terremotos en Chile', fontsize=16)\n",
    "plt.xlabel('Profundidad Focal (km)', fontsize=14)\n",
    "plt.ylabel('Magnitud (Escala Richter)', fontsize=14)\n",
    "plt.grid(True)\n",
    "pdf.savefig()  # Guardamos este gráfico en el PDF\n",
    "\n",
    "# Gráfico 6: Subgráfico de Daños Económicos vs. Año y Personas Afectadas vs. Año\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "ax1.scatter(df['Year'], df['Damage ($Mil)'], color='orange', label='Daños Económicos')\n",
    "ax1.set_title('Daños Económicos vs. Año')\n",
    "ax1.set_xlabel('Año')\n",
    "ax1.set_ylabel('Daños Económicos ($Mil)')\n",
    "ax1.legend()\n",
    "ax2.plot(df['Year'], df['Deaths'], color='red', label='Muertes')\n",
    "ax2.plot(df['Year'], df['Missing'], color='blue', label='Desaparecidos')\n",
    "ax2.plot(df['Year'], df['Injuries'], color='green', label='Heridos')\n",
    "ax2.set_title('Número de Personas Afectadas vs. Año')\n",
    "ax2.set_xlabel('Año')\n",
    "ax2.set_ylabel('Cantidad de Personas')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "pdf.savefig()  # Guardamos este gráfico en el PDF\n",
    "\n",
    "# Cerramos el PDF\n",
    "pdf.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
